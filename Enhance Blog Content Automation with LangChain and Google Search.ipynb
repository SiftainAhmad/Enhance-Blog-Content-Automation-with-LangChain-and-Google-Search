{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Enhance Blog Content Automation with LangChain and Google Search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Providing the Title, Context & Text that we want to expand "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iqr_NcHJ8cEK"
      },
      "outputs": [],
      "source": [
        "\"\"\"THREE VARIABLES IN TOTAL\"\"\"\n",
        "\n",
        "#Article's Title\n",
        "title = \"OpenAI CEO: AI regulation ‘is essential’\"\n",
        "# Content\n",
        "text_all = \"\"\" Altman highlighted the potential benefits of AI technologies like ChatGPT and Dall-E 2 to help address significant challenges such as climate change and cancer, but he also stressed the need to mitigate the risks associated with increasingly powerful AI models. Altman proposed that governments consider implementing licensing and testing requirements for AI models that surpass a certain threshold of capabilities. He highlighted OpenAI’s commitment to safety and extensive testing before releasing any new systems, emphasising the company’s belief that ensuring the safety of AI is crucial. Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. Blumenthal raised concerns about various risks associated with AI, including deepfakes, weaponised disinformation, discrimination, harassment, and impersonation fraud. He also emphasised the potential displacement of workers in the face of a new industrial revolution driven by AI.\"\"\"\n",
        "# Part of the text we want to expand upon\n",
        "text_to_change = \"\"\" Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Instailling Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6Hafr2g9WS9",
        "outputId": "7a0f46c8-52bc-4d60-83a7-811feed7d298"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain==0.0.208 in /usr/local/lib/python3.10/dist-packages (0.0.208)\n",
            "Requirement already satisfied: deeplake in /usr/local/lib/python3.10/dist-packages (3.9.10)\n",
            "Requirement already satisfied: openai==0.27.8 in /usr/local/lib/python3.10/dist-packages (0.27.8)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (0.5.14)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (0.0.20)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (2.10.0)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (1.25.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (1.10.16)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain==0.0.208) (8.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.27.8) (4.66.4)\n",
            "Requirement already satisfied: pillow~=10.2.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (10.2.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.34.106)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from deeplake) (8.1.7)\n",
            "Requirement already satisfied: pathos in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\n",
            "Requirement already satisfied: humbug>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.3.2)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.10/dist-packages (from deeplake) (4.3.3)\n",
            "Requirement already satisfied: pyjwt in /usr/lib/python3/dist-packages (from deeplake) (2.3.0)\n",
            "Requirement already satisfied: libdeeplake==0.0.133 in /usr/local/lib/python3.10/dist-packages (from deeplake) (0.0.133)\n",
            "Requirement already satisfied: aioboto3>=10.4.0 in /usr/local/lib/python3.10/dist-packages (from deeplake) (13.0.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.10/dist-packages (from deeplake) (1.6.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from libdeeplake==0.0.133->deeplake) (0.3.8)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: aiobotocore[boto3]==2.13.0 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (2.13.0)\n",
            "Requirement already satisfied: aiofiles>=23.2.1 in /usr/local/lib/python3.10/dist-packages (from aioboto3>=10.4.0->deeplake) (23.2.1)\n",
            "Requirement already satisfied: botocore<1.34.107,>=1.34.70 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.34.106)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.14.1)\n",
            "Requirement already satisfied: aioitertools<1.0.0,>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (0.11.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.0.208) (1.9.4)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3->deeplake) (0.10.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain==0.0.208) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.208) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.208) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.208) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.208) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.208) (3.0.3)\n",
            "Requirement already satisfied: ppft>=1.7.6.8 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (1.7.6.8)\n",
            "Requirement already satisfied: pox>=0.3.4 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.3.4)\n",
            "Requirement already satisfied: multiprocess>=0.70.16 in /usr/local/lib/python3.10/dist-packages (from pathos->deeplake) (0.70.16)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.34.107,>=1.34.70->aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (2.8.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (24.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.208) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.34.107,>=1.34.70->aiobotocore[boto3]==2.13.0->aioboto3>=10.4.0->deeplake) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain==0.0.208 deeplake openai==0.27.8 tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ALr-ZcDW-DR_"
      },
      "outputs": [],
      "source": [
        "!pip install -q newspaper3k==0.2.8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting Up OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "JMj0EBrK-Gl-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY']='sk-proj-K74wTeg5dakjdls;asdnXovwvk5OCUFVxIm'\n",
        "\n",
        "os.environ['ACTIVELOOP_TOKEN']='eyJhbGciOiJub25ldkslkdsa;ksdldsklkdfpZnRhaW4iLCJhcGlfa2V5IjoiLXVpdU9rN0pOT18zZ3ZnTFk1TTEtVGxEVUdTUDcwTlNEWGRMbzIzcVVWTjJlIn0.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Generating Search Queries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ojcjf-G4-hhY"
      },
      "outputs": [],
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "template = \"\"\" You are an exceptional copywriter and content creator.\n",
        "\n",
        "You're reading an article with the following title:\n",
        "----------------\n",
        "{title}\n",
        "----------------\n",
        "\n",
        "You've just read the following piece of text from that article.\n",
        "----------------\n",
        "{text_all}\n",
        "----------------\n",
        "\n",
        "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
        "----------------\n",
        "{text_to_change}\n",
        "----------------\n",
        "\n",
        "What are some simple and high-level Google queries that you'd do to search for more info to add to that paragraph?\n",
        "Write 3 queries as a bullet point list, prepending each line with -.\n",
        "\"\"\"\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=[\"text_to_change\", \"text_all\", \"title\"],\n",
        "    )\n",
        ")\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initiating the model and temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9bqOBLxf-2pc"
      },
      "outputs": [],
      "source": [
        "# model’s temperature argument to 0.9 which makes it highly creative, so it generates more diverse results\n",
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
        "\n",
        "response = chain.run({\n",
        "    \"text_to_change\": text_to_change,\n",
        "    \"text_all\": text_all,\n",
        "    \"title\": title\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgnsZDqZ_THx",
        "outputId": "15ac5292-c40d-4520-94ce-583e85cf558a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['AI voice cloning software uses in politics', 'AI technology impact on elections and security', \"Senators' perspectives on AI regulation and ethics\"]\n"
          ]
        }
      ],
      "source": [
        "queries = [line[2:] for line in response.split(\"\\n\")]\n",
        "print(queries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Setting up GOOGLE_API_KEY & GOOGLE_CSE_ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "RDBFYpxYARGw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyASkjdsklk;lkl;;R7Liu4p0cPp4i8IrzspA\"\n",
        "os.environ[\"GOOGLE_CSE_ID\"] = \"25dkdsll;;;;;;;4ac1\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Getting  Search Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "XWRit80MAWch"
      },
      "outputs": [],
      "source": [
        "from langchain.tools import Tool\n",
        "from langchain.utilities import GoogleSearchAPIWrapper\n",
        "\n",
        "# Remember to set the \"GOOGLE_CSE_ID\" and \"GOOGLE_API_KEY\" environment variable.\n",
        "search = GoogleSearchAPIWrapper()\n",
        "TOP_N_RESULTS = 5\n",
        "\n",
        "def top_n_results(query):\n",
        "    return search.results(query, TOP_N_RESULTS)\n",
        "\n",
        "tool = Tool(\n",
        "    name = \"Google Search\",\n",
        "    description=\"Search Google for recent results.\",\n",
        "    func=top_n_results\n",
        ")\n",
        "\n",
        "all_results = []\n",
        "\n",
        "for query in queries:\n",
        "    results = tool.run(query)\n",
        "    all_results += results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_8EJyRyRAiCP"
      },
      "outputs": [],
      "source": [
        "# print(all_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14QheEcpBfTV",
        "outputId": "0d73a3e9-91c3-4995-cdba-7178eeb371d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: AI voice clones mimic politicians and celebrities, reshaping reality\n",
            "Link: https://www.washingtonpost.com/technology/2023/10/13/ai-voice-cloning-deepfakes/\n",
            "Snippet: Oct 13, 2023 ... Meanwhile, few software companies have guardrails to prevent illicit use. Previously, voice cloning software churned out robotic ...\n",
            "\n",
            "Title: My Journey Inside ElevenLabs' Voice-Clone Factory - The Atlantic\n",
            "Link: https://www.theatlantic.com/technology/archive/2024/05/elevenlabs-ai-voice-cloning-deepfakes/678288/\n",
            "Snippet: May 4, 2024 ... ... voice but the way the software uses context clues to modulate delivery. If ... ” Voice cloning already existed, but it was crude: I used an AI ...\n",
            "\n",
            "Title: Tests find AI tools readily create election lies from the voices of well ...\n",
            "Link: https://apnews.com/article/artificial-intelligence-audio-voice-cloning-elections-2024-2500813b642169478c27c168aab1b3e3\n",
            "Snippet: May 31, 2024 ... ... AI voice cloning tool. One tool, Invideo AI, not only created the fake ... used its technology to sway public opinion on political issues.\n",
            "\n",
            "Title: Audio deepfakes of politicians are cheap and easy to make : NPR\n",
            "Link: https://www.npr.org/2024/05/30/nx-s1-4986088/deepfake-audio-elections-politics-ai\n",
            "Snippet: May 31, 2024 ... \"This report shows that AI-voice cloning tools…are wide-open to abuse in elections. ... ElevenLabs, the tech company whose software was used to ...\n",
            "\n",
            "Title: FCC bans AI-generated voices in robocalls that can deceive voters ...\n",
            "Link: https://www.pbs.org/newshour/politics/fcc-bans-ai-generated-voices-in-robocalls-that-can-deceive-voters\n",
            "Snippet: Feb 8, 2024 ... Sophisticated generative AI tools, from voice-cloning software to image generators, already are in use in elections in the U.S. and around the ...\n",
            "\n",
            "Title: How AI Puts Elections at Risk — And the Needed Safeguards ...\n",
            "Link: https://www.brennancenter.org/our-work/analysis-opinion/how-ai-puts-elections-risk-and-needed-safeguards\n",
            "Snippet: Jun 13, 2023 ... Forthcoming Brennan Center analyses will examine additional areas of risk, including voter suppression, election security, and the use of AI in ...\n",
            "\n",
            "Title: Artificial Intelligence (AI) and Election Administration | U.S. Election ...\n",
            "Link: https://www.eac.gov/AI\n",
            "Snippet: There are ongoing and developing efforts to try to lessen the impact of AI misuse and weaponization. AI Toolkit. Like any technology, AI tools are used for a ...\n",
            "\n",
            "Title: Artificial Intelligence and Election Security | Brennan Center for Justice\n",
            "Link: https://www.brennancenter.org/our-work/research-reports/artificial-intelligence-and-election-security\n",
            "Snippet: Oct 5, 2023 ... ... election outcomes in the AI age. Later pieces in this series will consider, among other issues, AI's effects on manipulated media in political ...\n",
            "\n",
            "Title: The ASD AI Election Security Handbook | German Marshall Fund of ...\n",
            "Link: https://www.gmfus.org/news/asd-ai-election-security-handbook\n",
            "Snippet: Feb 13, 2024 ... As the 2024 US presidential cycle hits its stride, election officials face a new technological challenge amid declining public confidence in ...\n",
            "\n",
            "Title: Impact of Artificial Intelligence on Elections - R Street Institute\n",
            "Link: https://www.rstreet.org/research/impact-of-artificial-intelligence-on-elections/\n",
            "Snippet: Jun 11, 2024 ... Similarly, technology companies are outlining detailed agendas for how they plan to mitigate harm from deceptive AI election content.\n",
            "\n",
            "Title: Artificial Intelligence Ethics Framework for the Intelligence ... - INTEL\n",
            "Link: https://www.intelligence.gov/artificial-intelligence-ethics-framework-for-the-intelligence-community\n",
            "Snippet: ... perspectives, and professional skills. Agencies should also ensure that ... regulatory provisions? What authorities or agreements apply to the AI itself ...\n",
            "\n",
            "Title: Blueprint for an AI Bill of Rights | OSTP | The White House\n",
            "Link: https://www.whitehouse.gov/ostp/ai-bill-of-rights/\n",
            "Snippet: This protection should include proactive equity assessments as part of the system design, use of representative data and protection against proxies for ...\n",
            "\n",
            "Title: Japan's Approach to AI Regulation and Its Impact on the 2023 G7 ...\n",
            "Link: https://www.csis.org/analysis/japans-approach-ai-regulation-and-its-impact-2023-g7-presidency\n",
            "Snippet: Feb 14, 2023 ... ... perspective of regulation for AI. Regulation on ... AI Ethics Impact Assessment and released examples of its application to representative cases.\n",
            "\n",
            "Title: Artificial Intelligence in Vermont | Agency of Digital Services\n",
            "Link: http://digitalservices.vermont.gov/ai\n",
            "Snippet: ... Artificial Intelligence in Vermont from their unique perspectives. The ... Adopt the Code of Ethics; Recommended approach to Data Privacy and AI; Employee Use ...\n",
            "\n",
            "Title: Ethics guidelines for trustworthy AI | Shaping Europe's digital future\n",
            "Link: https://digital-strategy.ec.europa.eu/en/library/ethics-guidelines-trustworthy-ai\n",
            "Snippet: Apr 8, 2019 ... (1) lawful - respecting all applicable laws and regulations. (2) ... In-depth interviews with a number of representative organisations to gather ...\n"
          ]
        }
      ],
      "source": [
        "# all_results variable holds 15 web addresses. (3 queries from ChatGPT x 5 top Google search results)\n",
        "formatted_results = [\n",
        "    f\"Title: {result['title']}\\nLink: {result['link']}\\nSnippet: {result['snippet']}\"\n",
        "    for result in all_results\n",
        "]\n",
        "# Join the formatted results with double newline characters and print them\n",
        "print(\"\\n\\n\".join(formatted_results))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "zRwHY9KmBfrw"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# The all_results variable contains 15 web addresses (3 queries from ChatGPT x 5 top Google search results). However, it's not optimal to use all the contents due to several considerations:\n",
        "\n",
        "# 1. Token Limitations: LLMs have input length restrictions ranging from 2K to 4K tokens, depending on the model. While different chain types can overcome this, adhering to the model's window size is more efficient and yields better outcomes.\n",
        "\n",
        "# 2. Cost: Providing more words to the API increases costs, as model usage is determined by token count. Dividing a prompt into multiple chains is possible but costly.\n",
        "\n",
        "# 3. Relevance: The content from stored search results will likely be similar in context, so it's better to use the most relevant results to maintain efficiency and relevance.\n",
        "# \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding  the Most Relevant Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nADKbwNVDX_S"
      },
      "outputs": [],
      "source": [
        "# newspaper package can extract the contents of a web link using the .parse() method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAamgPJyDeR-",
        "outputId": "7c4df823-474b-4ec4-9e39-dab00681af23"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of pages:  15\n"
          ]
        }
      ],
      "source": [
        "import newspaper\n",
        "\n",
        "pages_content = []\n",
        "\n",
        "for result in all_results:\n",
        "\ttry:\n",
        "\t\tarticle = newspaper.Article(result[\"link\"])\n",
        "\t\tarticle.download()\n",
        "\t\tarticle.parse()\n",
        "\n",
        "\t\tif len(article.text) > 0:\n",
        "\t\t\tpages_content.append({ \"url\": result[\"link\"], \"text\": article.text })\n",
        "\texcept:\n",
        "\t\tcontinue\n",
        "\n",
        "print(\"Number of pages: \", len(pages_content))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lAR7_eTqDmIm"
      },
      "outputs": [],
      "source": [
        "# The output above shows that 14/15 pages were processed while we expected 15.\n",
        "#  There are specific scenarios in which the newspaper library may encounter\n",
        "#  difficulties extracting information.\n",
        "#  These include search results that lead to a PDF file\n",
        "#  or websites that restrict access to web scraping."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### split the saved contents into smaller chunks to ensure the articles do not exceed the model’s input length.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__MrEQuuD42w",
        "outputId": "3061aaf5-bc11-4d8d-9f7f-461304ecbd52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of chunks:  72\n"
          ]
        }
      ],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=100)\n",
        "\n",
        "docs = []\n",
        "for d in pages_content:\n",
        "    chunks = text_splitter.split_text(d[\"text\"])\n",
        "    for chunk in chunks:\n",
        "        new_doc = Document(page_content=chunk, metadata={ \"source\": d[\"url\"] })\n",
        "        docs.append(new_doc)\n",
        "\n",
        "print(\"Number of chunks: \", len(docs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kq_RyF2OD_XL"
      },
      "outputs": [],
      "source": [
        "# 72 chunks of data are in the docs variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Time to find the most relevant chunks to pass them as context to the large language model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "_MNMHgDgERnN"
      },
      "outputs": [],
      "source": [
        "# will use OpenAI to convert the texts into vector space that holds semantics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "qukKJY4EEmH4"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
        "# Embedding document chunks\n",
        "docs_embeddings = embeddings.embed_documents([doc.page_content for doc in docs])\n",
        "# Embedding desired sentence from the main article that was chosen for expansion\n",
        "query_embedding = embeddings.embed_query(text_to_change)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Xlyeg7u4E1UX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_top_k_indices(list_of_doc_vectors, query_vector, top_k):\n",
        "    # convert the lists of vectors to numpy arrays\n",
        "    list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
        "    query_vector = np.array(query_vector)\n",
        "\n",
        "    # compute cosine similarities\n",
        "    similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
        "\n",
        "    # sort the vectors based on cosine similarity\n",
        "    sorted_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "    # retrieve the top K indices from the sorted list\n",
        "    top_k_indices = sorted_indices[:top_k]\n",
        "\n",
        "    return top_k_indices\n",
        "\n",
        "top_k = 3\n",
        "best_indexes = get_top_k_indices(docs_embeddings, query_embedding, top_k)\n",
        "best_k_documents = [doc for i, doc in enumerate(docs) if i in best_indexes]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Top 3 documents as specified"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj3ttk7PFFRZ",
        "outputId": "7cf40204-2877-4a5e-a123-2904ea9f082d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='The other companies cited in the report didn’t respond to emailed requests for comment.\\n\\nThe findings come after AI-generated audio clips already have been used in attempts to sway voters in elections across the globe.\\n\\nIn fall 2023, just days before Slovakia’s parliamentary elections, audio clips resembling the voice of the liberal party chief were shared widely on social media. The deepfakes purportedly captured him talking about hiking beer prices and rigging the vote.\\n\\nEarlier this year, AI-generated robocalls mimicked Biden’s voice and told New Hampshire primary voters to stay home and “save” their votes for November. A New Orleans magician who created the audio for a Democratic political consultant demonstrated to the AP how he made it, using ElevenLabs software.\\n\\nExperts say AI-generated audio has been an early preference for bad actors, in part because the technology has improved so quickly. Only a few seconds of real audio are needed to create a lifelike fake.\\n\\nYet other forms of AI-generated media also are concerning experts, lawmakers and tech industry leaders. OpenAI, the company behind ChatGPT and other popular generative AI tools, revealed on Thursday that it had spotted and interrupted five online campaigns that used its technology to sway public opinion on political issues.\\n\\nAhmed, the CEO of the Center for Countering Digital Hate, said he hopes AI voice-cloning platforms will tighten security measures and be more proactive about transparency, including publishing a library of audio clips they have created so they can be checked when suspicious audio is spreading online.\\n\\nHe also said lawmakers need to act. The U.S. Congress has not yet passed legislation regulating AI in elections. While the E.U. has passed a wide-ranging artificial intelligence law set to go into effect over the next two years, it does not address voice-cloning tools specifically.\\n\\n“Lawmakers need to work to ensure there are minimum standards,” Ahmed said. “The threat that disinformation poses to our elections is not just the potential of causing a minor political incident, but making people distrust what they see and hear, full stop.”\\n\\n___\\n\\nThe Associated Press receives support from several private foundations to enhance its explanatory coverage of elections and democracy. See more about AP’s democracy initiative here. The AP is solely responsible for all content.', metadata={'source': 'https://apnews.com/article/artificial-intelligence-audio-voice-cloning-elections-2024-2500813b642169478c27c168aab1b3e3'}),\n",
              " Document(page_content='“In my day,” began a voice endorsing a laissez-faire approach to police brutality, “no one would bat an eye” if a police officer killed 17 or 18 people. The voice in the video, which purportedly belonged to Chicago mayoral candidate Paul Vallas, went viral just before the city’s four-way primary in February.\\n\\nIt wasn’t a gaffe, a leak, or a hot-mic moment. It seemingly wasn’t even the work of a sly impersonator who had perfected his Paul Vallas impression. The video was a digital fabrication, a likely creation of generative artificial intelligence that was viewed thousands of times.\\n\\nThe episode heralds a new era in elections. Next year will bring the first national campaign season in which widely accessible AI tools allow users to synthesize audio in anyone’s voice, generate photo-realistic images of anybody doing nearly anything, and power social media bot accounts with near human-level conversational abilities — and do so on a vast scale and with a reduced or negligible investment of money and time. Due to the popularization of chatbots and the search engines they are quickly being absorbed into, it will also be the first election season in which large numbers of voters routinely consume information that is not just curated by AI but is produced by AI.\\n\\nThis change is already underway. In April, the Republican National Committee used AI to produce a video warning about potential dystopian crises during a second Biden term. Earlier this year, an AI-generated video showing President Biden declaring a national draft to aid Ukraine’s war effort — originally acknowledged as a deepfake but later stripped of that context — led to a misleading tweet that garnered over 8 million views. A deepfake also circulated depicting Sen. Elizabeth Warren (D-MA) insisting that Republicans should be barred from voting in 2024. In the future, malign actors could deploy generative AI with the intent to suppress votes or circumvent defenses that secure elections.\\n\\nThe AI challenge to elections is not limited to disinformation, or even to deliberate mischief. Many elections offices use algorithmic systems to maintain voter registration databases and verify mail ballot signatures, among other tasks. As with human decisions on these questions, algorithmic decision-making has the potential for racial and other forms of bias. There is growing interest by some officials in using generative AI to aid with voter education, creating opportunities to speed up processes but also producing serious risks for inaccurate and inequitable voter outreach.\\n\\nAI advances have prompted an abundance of generalized concerns from the public and policymakers, but the impact of AI on the field of elections has received relatively little in-depth scrutiny given the outsize risk. This piece focuses on disinformation risks in 2024. Forthcoming Brennan Center analyses will examine additional areas of risk, including voter suppression, election security, and the use of AI in administering elections.', metadata={'source': 'https://www.brennancenter.org/our-work/analysis-opinion/how-ai-puts-elections-risk-and-needed-safeguards'}),\n",
              " Document(page_content='Overview: Artificial Intelligence and Elections\\n\\nAI refers to the “capability of computer systems or algorithms to imitate intelligent human behavior.” The term dates back to the 1950s, and AI capabilities have grown alongside improvements in computing overall. In recent years, AI sophistication has accelerated rapidly while the costs associated with accessing it have declined.\\n\\nAI is already integrated into many aspects of the U.S. economy, and many people interact with AI tools in their daily life. For example, banks use AI to assist in a variety of functions including fraud protection and credit underwriting. Email services like Gmail utilize AI to block unwanted spam messages, and ecommerce websites like Amazon use AI to connect individual shoppers with the products they are seeking. Yet, despite its existing integration in the background of modern life, AI recently entered the public consciousness in a more direct way with the release of OpenAI’s ChatGPT, a chatbot that can create written content and produce highly realistic audio recordings, photos, and videos using “generative AI” tools. When AI is used to imitate well-known people, particularly for nefarious purposes, the result is known as a “deepfake.”\\n\\nFrom an election perspective, these advances in AI technology are likely to impact the overall information environment, cybersecurity, and administrative processes. Although this emerging technology has garnered attention largely for its risks, as we outline below, there are also significant potential benefits to leveraging AI in our election environment.\\n\\nInformation Environment\\n\\nAn election’s information environment is the most obvious area in which AI could have a potential impact. AI tools can empower users to generate and distribute false information quickly, convincingly, and at a very low cost. The information itself can range from sophisticated deepfake videos created through generative AI programs to simpler text- or image-based disinformation.\\n\\nIn terms of distribution, AI tools can enable bots to flood social media sites with an overwhelming wave of misinformation. AI technology can also be paired with other communication methods such as cell phones to create and deliver targeted deceptive robocalls. This misinformation could be technical, such as lies about changes to voter eligibility or the return deadline for absentee ballots, or political, such as a video of a candidate speech that never actually happened.\\n\\nSuch AI-generated misinformation has already entered our political sphere. During the lead-up to the 2024 New Hampshire Democratic primary, many voters received a robocall message discouraging them to vote from a voice that sounded like it belonged to President Joe Biden. However, investigators determined that the audio recording was generated by AI and commissioned by a supporter of Dean Phillips, one of Biden’s opponents in the primary election.', metadata={'source': 'https://www.rstreet.org/research/impact-of-artificial-intelligence-on-elections/'})]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_k_documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "WmntJKluFoTt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "mtaAirFXF_Pm"
      },
      "outputs": [],
      "source": [
        "# \"\"\"We can now define the prompt using the additional information from Google search.\n",
        "# There are six input variables in the template:\n",
        "\n",
        "# 1.title that holds the main article’s title;\n",
        "# 2.text_all to present the whole article we are working on;\n",
        "# 3.text_to_change is the selected part of the article that requires expansion;\n",
        "# 4.doc_1, 5.doc_2, 6.doc_3 to include the close Google search results as context.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### Initiating the template according to the new extended sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "jLa5X-DKGPes"
      },
      "outputs": [],
      "source": [
        "template = \"\"\"You are an exceptional copywriter and content creator.\n",
        "\n",
        "You're reading an article with the following title:\n",
        "----------------\n",
        "{title}\n",
        "----------------\n",
        "\n",
        "You've just read the following piece of text from that article.\n",
        "----------------\n",
        "{text_all}\n",
        "----------------\n",
        "\n",
        "Inside that text, there's the following TEXT TO CONSIDER that you want to enrich with new details.\n",
        "----------------\n",
        "{text_to_change}\n",
        "----------------\n",
        "\n",
        "Searching around the web, you've found this ADDITIONAL INFORMATION from distinct articles.\n",
        "----------------\n",
        "{doc_1}\n",
        "----------------\n",
        "{doc_2}\n",
        "----------------\n",
        "{doc_3}\n",
        "----------------\n",
        "\n",
        "Modify the previous TEXT TO CONSIDER by enriching it with information from the previous ADDITIONAL INFORMATION.\n",
        "\"\"\"\n",
        "\n",
        "human_message_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        template=template,\n",
        "        input_variables=[\"text_to_change\", \"text_all\", \"title\", \"doc_1\", \"doc_2\", \"doc_3\"],\n",
        "    )\n",
        ")\n",
        "chat_prompt_template = ChatPromptTemplate.from_messages([human_message_prompt])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "5r0bXTrqGnFE"
      },
      "outputs": [],
      "source": [
        "chat = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0.9)\n",
        "chain = LLMChain(llm=chat, prompt=chat_prompt_template)\n",
        "\n",
        "response = chain.run({\n",
        "    \"text_to_change\": text_to_change,\n",
        "    \"text_all\": text_all,\n",
        "    \"title\": title,\n",
        "    \"doc_1\": best_k_documents[0].page_content,\n",
        "    \"doc_2\": best_k_documents[1].page_content,\n",
        "    \"doc_3\": best_k_documents[2].page_content\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Final Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfYRYrkMGpQB",
        "outputId": "a5fa74b9-2605-4ce0-e8fe-7b9abdb36d99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Text to Change:   Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
            "Expanded Variation: Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security. Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology. This demonstration highlights the growing concerns around AI-generated audio clips being used to deceive and manipulate voters in elections worldwide. Recent incidents, like the sharing of deepfake audio clips resembling political figures discussing controversial topics or the use of AI-generated robocalls mimicking prominent voices to spread misinformation, showcase the potential dangers of this technology. Blumenthal's use of AI voice cloning software to showcase its capabilities underscores the urgent need for regulations and safeguards to prevent the misuse of AI in influencing elections and public opinion.\n"
          ]
        }
      ],
      "source": [
        "print(\"Text to Change: \", text_to_change)\n",
        "print(\"Expanded Variation:\", response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "T-tD_EWXGrDw"
      },
      "outputs": [],
      "source": [
        "def split_sentences(text):\n",
        "    sentences = text.split('. ')\n",
        "    return '.\\n'.join(sentences) + '.'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqYrdHY7HN91",
        "outputId": "27974fb6-f608-445d-e9ad-2930c3859814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text:\n",
            " Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
            "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology..\n",
            "\n",
            "Expanded Variation:\n",
            "Senators Josh Hawley and Richard Blumenthal expressed their recognition of the transformative nature of AI and the need to understand its implications for elections, jobs, and security.\n",
            "Blumenthal played an audio introduction using an AI voice cloning software trained on his speeches, demonstrating the potential of the technology.\n",
            "This demonstration highlights the growing concerns around AI-generated audio clips being used to deceive and manipulate voters in elections worldwide.\n",
            "Recent incidents, like the sharing of deepfake audio clips resembling political figures discussing controversial topics or the use of AI-generated robocalls mimicking prominent voices to spread misinformation, showcase the potential dangers of this technology.\n",
            "Blumenthal's use of AI voice cloning software to showcase its capabilities underscores the urgent need for regulations and safeguards to prevent the misuse of AI in influencing elections and public opinion..\n"
          ]
        }
      ],
      "source": [
        "# Print the results\n",
        "print(\"Original Text:\")\n",
        "print(split_sentences(text_to_change))\n",
        "print(\"\\nExpanded Variation:\")\n",
        "print(split_sentences(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Thank You"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
